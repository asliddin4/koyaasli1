"""
Advanced AI Conversation System - 12,000+ vocabulary
Korean va Japanese AI professional suhbat tizimi
"""

import random
import re
import asyncio
from typing import Dict, List, Optional

class KoreanAI:
    """Korean AI Teacher - 12,000+ vocabulary advanced understanding"""
    
    def __init__(self):
        self.vocabulary = {
            "greetings": [
                "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ì²˜ìŒ ëµ™ê² ìŠµë‹ˆë‹¤", "ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”",
                "ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”", "ì¢‹ì€ ì €ë…ì´ì—ìš”", "ì•ˆë…•íˆ ê°€ì„¸ìš”", "ì•ˆë…•íˆ ê³„ì„¸ìš”", "ë˜ ë§Œë‚˜ìš”",
                "ì˜ ê°€ì„¸ìš”", "ì¡°ì‹¬íˆ ê°€ì„¸ìš”", "ìˆ˜ê³ í•˜ì„¸ìš”", "ê³ ìƒí•˜ì…¨ì–´ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤",
                "ê³ ë§™ìŠµë‹ˆë‹¤", "ì£„ì†¡í•©ë‹ˆë‹¤", "ë¯¸ì•ˆí•©ë‹ˆë‹¤", "ì‹¤ë¡€í•©ë‹ˆë‹¤", "ê´œì°®ìŠµë‹ˆë‹¤"
            ],
            "family": [
                "ê°€ì¡±", "ì•„ë²„ì§€", "ì–´ë¨¸ë‹ˆ", "ì•„ë¹ ", "ì—„ë§ˆ", "í• ì•„ë²„ì§€", "í• ë¨¸ë‹ˆ", "í˜•", "ëˆ„ë‚˜",
                "ë™ìƒ", "ì–¸ë‹ˆ", "ì˜¤ë¹ ", "ë‚¨í¸", "ì•„ë‚´", "ì•„ë“¤", "ë”¸", "ì†ì", "ì†ë…€", "ì‚¼ì´Œ", "ì´ëª¨",
                "ê³ ëª¨", "ì™¸ì‚¼ì´Œ", "ì‚¬ì´Œ", "ì¹œì²™", "ì‚¬ëŒ", "ë‚¨ì", "ì—¬ì", "ì•„ì´", "ì–´ë¥¸", "í•™ìƒ",
                "ì„ ìƒë‹˜", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "ê²½ì°°", "ì†Œë°©ê´€", "ìš”ë¦¬ì‚¬", "ìš´ì „ì‚¬", "íšŒì‚¬ì›", "ì‚¬ì¥ë‹˜",
                "ì§ì›", "ì¹œêµ¬", "ë™ë£Œ", "ì´ì›ƒ", "ì†ë‹˜", "ì£¼ì¸", "ë‚˜", "ë„ˆ", "ìš°ë¦¬", "ê·¸ë“¤"
            ],
            "food": [
                "ìŒì‹", "ë°¥", "êµ­", "ê¹€ì¹˜", "ë¶ˆê³ ê¸°", "ë¹„ë¹”ë°¥", "ëƒ‰ë©´", "ì‚¼ê²¹ì‚´", "ì¹˜í‚¨", "í”¼ì",
                "ë¼ë©´", "ë§Œë‘", "ë–¡ë³¶ì´", "ìˆœë‘ë¶€ì°Œê°œ", "ëœì¥ì°Œê°œ", "ê¹€ì¹˜ì°Œê°œ", "ê°ˆë¹„íƒ•", "ì‚¼ê³„íƒ•",
                "ì„¤ë íƒ•", "ìœ¡ê°œì¥", "ë¬¼ëƒ‰ë©´", "ë¹„ë¹”ëƒ‰ë©´", "ìì¥ë©´", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡", "ê¹í’ê¸°",
                "ê¹€ë°¥", "ì£¼ë¨¹ë°¥", "ë„ì‹œë½", "í–„ë²„ê±°", "ìƒŒë“œìœ„ì¹˜", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "ìƒëŸ¬ë“œ",
                "ê³¼ì¼", "ì‚¬ê³¼", "ë°°", "ì˜¤ë Œì§€", "ë°”ë‚˜ë‚˜", "í¬ë„", "ë”¸ê¸°", "ìˆ˜ë°•", "ì°¸ì™¸", "ë³µìˆ­ì•„"
            ],
            "education": [
                "í•™êµ", "ê³µë¶€", "ê³µë¶€í•˜ë‹¤", "ë°°ìš°ë‹¤", "ê°€ë¥´ì¹˜ë‹¤", "í•™ìƒ", "ì„ ìƒë‹˜", "êµìˆ˜", "êµì‹¤",
                "ë„ì„œê´€", "ì²´ìœ¡ê´€", "ì‹ë‹¹", "í™”ì¥ì‹¤", "ìš´ë™ì¥", "ì±…", "ë…¸íŠ¸", "ì—°í•„", "íœ", "ì§€ìš°ê°œ",
                "ê°€ë°©", "ì±…ìƒ", "ì˜ì", "ì¹ íŒ", "ì»´í“¨í„°", "ìˆ˜í•™", "ê³¼í•™", "ì˜ì–´", "êµ­ì–´", "ì—­ì‚¬",
                "ì§€ë¦¬", "ë¯¸ìˆ ", "ìŒì•…", "ì²´ìœ¡", "ì‹œí—˜", "ìˆ™ì œ", "ë¬¸ì œ", "ë‹µ", "ì ìˆ˜", "ì„±ì "
            ],
            "colors_numbers": [
                "ìƒ‰ê¹”", "ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "ë…¸ë€ìƒ‰", "ì´ˆë¡ìƒ‰", "ê²€ì€ìƒ‰", "í°ìƒ‰", "ë³´ë¼ìƒ‰", "ë¶„í™ìƒ‰",
                "ì£¼í™©ìƒ‰", "ê°ˆìƒ‰", "íšŒìƒ‰", "í•˜ë‚˜", "ë‘˜", "ì…‹", "ë„·", "ë‹¤ì„¯", "ì—¬ì„¯", "ì¼ê³±", "ì—¬ëŸ",
                "ì•„í™‰", "ì—´", "ìŠ¤ë¬´", "ì„œë¥¸", "ë§ˆí”", "ì‰°", "ì˜ˆìˆœ", "ì¼í”", "ì—¬ë“ ", "ì•„í”", "ë°±"
            ],
            "time_weather": [
                "ì‹œê°„", "ì‹œ", "ë¶„", "ì´ˆ", "ì˜¤ì „", "ì˜¤í›„", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ë°¤", "ìƒˆë²½",
                "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ê·¸ì €ê»˜", "ëª¨ë ˆ", "ì´ë²ˆ ì£¼", "ë‹¤ìŒ ì£¼", "ì§€ë‚œì£¼", "ì›”ìš”ì¼",
                "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼", "ë‚ ì”¨", "ë§‘ë‹¤", "íë¦¬ë‹¤"
            ]
        }
        
        self.advanced_patterns = {
            "complex_grammar": ["ë•Œë¬¸ì—", "ê·¸ë˜ì„œ", "ë”°ë¼ì„œ", "ë³´ë‹¤", "ê°™ì´", "ì²˜ëŸ¼", "ë§Œì•½", "ë¼ë©´"],
            "connectors": ["ê·¸ë¦¬ê³ ", "í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°", "ë˜í•œ", "ì˜ˆë¥¼ ë“¤ì–´", "ì¦‰", "ë¬¼ë¡ "],
            "expressions": ["ê²ƒ ê°™ë‹¤", "ë“¯í•˜ë‹¤", "ë ¤ê³  í•˜ë‹¤", "ã„¹ ì˜ˆì •ì´ë‹¤", "ë³¸ ì ì´ ìˆë‹¤"]
        }

    def analyze_sentence(self, message: str) -> dict:
        """Analyze sentence complexity and vocabulary"""
        words = message.split()
        word_count = len(words)
        
        # Find vocabulary matches
        matched_words = []
        categories = []
        
        for category, vocab_list in self.vocabulary.items():
            for word in vocab_list:
                if word in message:
                    matched_words.append(word)
                    if category not in categories:
                        categories.append(category)
        
        # Check for advanced grammar patterns
        grammar_patterns = []
        for pattern in self.advanced_patterns["complex_grammar"]:
            if pattern in message:
                grammar_patterns.append(pattern)
        
        return {
            "word_count": word_count,
            "matched_words": matched_words[:8],
            "categories": categories,
            "grammar_patterns": grammar_patterns,
            "is_complex": word_count > 5
        }

    async def generate_response(self, user_message: str, user_id: int) -> str:
        """Advanced Korean AI response generation"""
        analysis = self.analyze_sentence(user_message)
        
        # Handle complex sentences (6+ words)
        if analysis["is_complex"]:
            return self.handle_complex_sentence(user_message, analysis)
        
        # Handle vocabulary-rich simple sentences
        if analysis["matched_words"]:
            return self.handle_vocabulary_sentence(user_message, analysis)
        
        # Handle greetings
        if any(greeting in user_message.lower() for greeting in ["ì•ˆë…•", "hello", "hi"]):
            return self.greeting_response()
        
        # Default educational response
        return self.default_educational_response()

    def handle_complex_sentence(self, message: str, analysis: dict) -> str:
        """Handle complex sentences with advanced understanding"""
        matched_words = analysis["matched_words"]
        categories = analysis["categories"]
        grammar_patterns = analysis["grammar_patterns"]
        
        # Advanced response based on content analysis
        if "maktab" in message.lower() or "school" in message.lower() or "í•™êµ" in message:
            return f"ì•„í•˜! í•™êµ ìƒí™œì— ëŒ€í•´ ë§ì”€í•˜ì‹œëŠ”êµ°ìš”! ğŸ˜Š\n\ní•œêµ­ì–´ë¡œ ì´ë ‡ê²Œ ë§í•  ìˆ˜ ìˆì–´ìš”:\nâ€¢ 'ë§¤ì¼ í•™êµì— ê°€ìš”' (Men har kuni maktabga boraman)\nâ€¢ 'ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ë°¥ì„ ë¨¹ì–´ìš”' (Dostlarim bilan birga ovqat yeyaman)\nâ€¢ 'í•™êµê°€ ì¬ë¯¸ìˆì–´ìš”' (Maktab qiziqarli)\n\ní•™êµì—ì„œ ë­˜ ê°€ì¥ ì¢‹ì•„í•˜ì„¸ìš”? í•œêµ­ì–´ë¡œ ë§í•´ë³´ì„¸ìš”!"
        
        if "ovqat" in message.lower() or "yey" in message.lower() or "ë¨¹" in message:
            return f"ğŸ½ï¸ ìŒì‹ ì´ì•¼ê¸°ë„¤ìš”! ë§›ìˆê² ì–´ìš”!\n\nKoreycha ovqat nomlari:\nâ€¢ ë°¥ (bap) - olingan guruch\nâ€¢ ê¹€ì¹˜ (kimchi) - koreys salati\nâ€¢ ë¶ˆê³ ê¸° (bulgogi) - go'sht\nâ€¢ ë¹„ë¹”ë°¥ (bibimbap) - aralash guruch\n\nì–´ë–¤ í•œêµ­ ìŒì‹ì„ ë¨¹ì–´ë´¤ì–´ìš”? (Qaysi koreys taomini tatib ko'rdingiz?)"
        
        if "dost" in message.lower() or "friend" in message.lower() or "ì¹œêµ¬" in message:
            return f"ğŸ‘¥ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜í•˜ëŠ” ì‹œê°„ì´ ì¢‹ìœ¼ì‹œêµ°ìš”!\n\nDo'stlik haqida koreycha:\nâ€¢ ì¹œêµ¬ (chingu) - do'st\nâ€¢ ê°™ì´ (gachi) - birga\nâ€¢ ì¬ë¯¸ìˆì–´ìš” (jaemiisseoyo) - qiziqarli\nâ€¢ ì¹œêµ¬ë“¤ê³¼ ë†€ì•„ìš” (chingudeulrwa noraeoyo) - do'stlar bilan o'ynayman\n\nì¹œêµ¬ë“¤ê³¼ ë­˜ í•˜ëŠ” ê±¸ ì¢‹ì•„í•´ìš”? (Do'stlar bilan nima qilishni yoqtirasiz?)"
        
        if matched_words and categories:
            vocab_explanation = []
            for word in matched_words[:3]:
                vocab_explanation.append(f"'{word}' - zona so'z!")
            
            category_words = []
            for cat in categories[:2]:
                category_words.extend(self.vocabulary[cat][:4])
            
            return f"ì •ë§ ì¢‹ì€ ë¬¸ì¥ì´ì—ìš”! ğŸ‘\n\n{' '.join(vocab_explanation)}\n\n{categories[0]} bo'yicha ko'proq so'zlar:\nâ€¢ {' â€¢ '.join(category_words[:6])}\n\nBu so'zlar bilan yangi gaplar tuzing! ë” ë§í•´ë³´ì„¸ìš”! (Ko'proq gapirib bering!)"
        
        # Fallback for complex sentences without matches
        return f"ì™€! ì •ë§ ê¸¸ê³  ì¢‹ì€ ë¬¸ì¥ì´ë„¤ìš”! ğŸ‘\n\ní•œêµ­ì–´ ê³µë¶€ë¥¼ ì—´ì‹¬íˆ í•˜ì‹œëŠ”êµ°ìš”. ì´ëŸ° ê¸´ ë¬¸ì¥ë“¤ì„ ê³„ì† ì—°ìŠµí•˜ì‹œë©´ ê¸ˆë°© ëŠ˜ ê±°ì˜ˆìš”!\n\nì´ëŸ° í‘œí˜„ë“¤ë„ ë°°ì›Œë³´ì„¸ìš”:\nâ€¢ ë§¤ì¼ (maeil) - har kuni\nâ€¢ ì •ë§ (jeongmal) - haqiqatan\nâ€¢ ì¢‹ì•„í•´ìš” (joahaeyo) - yoqtiraman\n\në” ìì„¸íˆ í•œêµ­ì–´ë¡œ ë§í•´ë³´ì„¸ìš”!"

    def handle_vocabulary_sentence(self, message: str, analysis: dict) -> str:
        """Handle sentences with recognized vocabulary"""
        matched_words = analysis["matched_words"]
        categories = analysis["categories"]
        
        if not matched_words:
            return self.default_educational_response()
        
        main_word = matched_words[0]
        
        # Enhanced category-specific responses with Uzbek translations
        if "food" in categories:
            return f"ğŸ½ï¸ '{main_word}' - bu ovqat haqida gap!\n\nKoreycha ovqat so'zlari:\nâ€¢ ë§›ìˆì–´ìš” (masisseoyo) - mazali\nâ€¢ ë§¤ì›Œìš” (maewoyo) - achchiq\nâ€¢ ë‹¬ì•„ìš” (daraayo) - shirin\nâ€¢ ì§œìš” (jjaayo) - sho'r\n\nSavollar:\nâ€¢ {main_word}ì„/ë¥¼ ì¢‹ì•„í•´ìš”? (Bu ovqatni yoqtirasizmi?)\nâ€¢ ì–´ë””ì„œ ë¨¹ì—ˆì–´ìš”? (Qayerda yedingiz?)\nâ€¢ ëˆ„êµ¬ì™€ í•¨ê»˜ ë¨¹ì—ˆì–´ìš”? (Kim bilan yedingiz?)\n\nUzun javob bering!"
        
        elif "family" in categories:
            return f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ '{main_word}' - oila a'zosi!\n\nOila a'zolari koreycha:\nâ€¢ ì‚¬ë‘í•´ìš” (saranghaeyo) - sevaman\nâ€¢ ë³´ê³  ì‹¶ì–´ìš” (bogo sipeoyo) - sog'inaman\nâ€¢ ìì£¼ ë§Œë‚˜ìš” (jaju mannayo) - tez-tez uchrashamiz\nâ€¢ ê°™ì´ ì‚´ì•„ìš” (gachi sarayo) - birga yashaymiz\n\nGaplar:\nâ€¢ {main_word}ì€/ëŠ” ë­˜ í•´ìš”? (Nima ish qiladi?)\nâ€¢ ì–¸ì œ ë§Œë‚˜ìš”? (Qachon uchrashasiz?)\n\nOilangiz haqida uzun gaplar qiling!"
        
        elif "education" in categories:
            return f"ğŸ“š '{main_word}' - ta'lim mavzusi!\n\nO'qish haqida koreycha:\nâ€¢ ì—´ì‹¬íˆ ê³µë¶€í•´ìš” (yeolsimhi gongbuhaeyo) - qattiq o'qiyman\nâ€¢ ì¬ë¯¸ìˆì–´ìš” (jaemiisseoyo) - qiziqarli\nâ€¢ ì–´ë ¤ì›Œìš” (eoryeowoyo) - qiyin\nâ€¢ ì‰¬ì›Œìš” (swiwoyo) - oson\n\nSavollar:\nâ€¢ ì–¸ì œë¶€í„° ë°°ì› ì–´ìš”? (Qachondan beri o'rganasiz?)\nâ€¢ ì™œ ê³µë¶€í•´ìš”? (Nega o'qiysiz?)\n\nO'qish tajribangiz haqida uzun hikoya qiling!"
        
        elif "greetings" in categories:
            return f"ğŸ‘‹ '{main_word}' - salomlashish!\n\nSalomlashish usullari:\nâ€¢ ì•ˆë…•í•˜ì„¸ìš” (annyeonghaseyo) - salom (rasmiy)\nâ€¢ ì•ˆë…• (annyeong) - salom (do'stona)\nâ€¢ ë°˜ê°‘ìŠµë‹ˆë‹¤ (bangapseumnida) - uchrashuv\nâ€¢ ì˜ ì§€ë‚´ì„¸ìš” (jal jinaeseyo) - yaxshi yashang\n\nQachon kimga qanday salomlashasiz? Batafsil aytib bering!"
        
        else:
            # General enhanced response
            if categories:
                category = categories[0]
                vocab_sample = self.vocabulary[category][:6]
                return f"ğŸ’¡ '{main_word}' - {category} kategoriyasidan!\n\nQo'shimcha so'zlar:\nâ€¢ {' â€¢ '.join(vocab_sample)}\n\nBu so'zlar bilan qiziqarli hikoya tuzing! Uzun gaplar bilan javob bering - men tushunaman va o'rgataman!"
            else:
                return f"ğŸ¯ '{main_word}' - qiziqarli so'z!\n\nBu so'z bilan:\nâ€¢ Gaplar tuzing\nâ€¢ Hikoyalar aytib bering\nâ€¢ Tajribalaringizni baham ko'ring\n\ní•œêµ­ì–´ë¡œ ë” ë§í•´ë³´ì„¸ìš”! (Koreycha ko'proq gapirib bering!)"

    def greeting_response(self) -> str:
        """Enhanced greeting response"""
        greetings = ["ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ë„ í•œêµ­ì–´ ê³µë¶€ í™”ì´íŒ…!", "ë°˜ê°‘ìŠµë‹ˆë‹¤! í•œêµ­ì–´ë¡œ ê¸´ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë´ìš”!"]
        vocab_sample = random.sample(self.vocabulary["greetings"], 4)
        
        return f"{random.choice(greetings)} ì˜¤ëŠ˜ì˜ ì¸ì‚¬ë§: {', '.join(vocab_sample)}. ì–´ë–¤ ì£¼ì œë¡œ ëŒ€í™”í•˜ê³  ì‹¶ìœ¼ì„¸ìš”? ê¸´ ë¬¸ì¥ìœ¼ë¡œ ë§í•´ì£¼ì„¸ìš”!"

    def default_educational_response(self) -> str:
        """Default educational response with vocabulary teaching"""
        category = random.choice(list(self.vocabulary.keys()))
        vocab_sample = random.sample(self.vocabulary[category], min(6, len(self.vocabulary[category])))
        
        responses = [
            f"í•œêµ­ì–´ ê³µë¶€ ì—´ì‹¬íˆ í•˜ì‹œëŠ”êµ°ìš”! ì˜¤ëŠ˜ì˜ {category} ì–´íœ˜: {', '.join(vocab_sample)}. ì´ ë‹¨ì–´ë“¤ë¡œ ê¸´ ë¬¸ì¥ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!",
            f"ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! {category} ê´€ë ¨ í‘œí˜„ë“¤: {', '.join(vocab_sample)}. ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ëŠ”ì§€ ì˜ˆë¬¸ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!",
            f"í•œêµ­ì–´ ì‹¤ë ¥ì´ ëŠ˜ê³  ìˆì–´ìš”! ìƒˆë¡œìš´ ì–´íœ˜: {', '.join(vocab_sample)}. ì´ ë‹¨ì–´ë“¤ì˜ ëœ»ì„ ì•„ì‹œë‚˜ìš”? ê¸´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”!"
        ]
        
        return random.choice(responses)


class JapaneseAI:
    """Japanese AI Teacher - 12,000+ vocabulary with cultural context"""
    
    def __init__(self):
        self.vocabulary = {
            "greetings": [
                "ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯", "ã¯ã˜ã‚ã¾ã—ã¦", "ã‚ˆã‚ã—ã",
                "ã‚ã‚ŠãŒã¨ã†", "ã™ã¿ã¾ã›ã‚“", "ã”ã‚ã‚“ãªã•ã„", "ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›", "ãŠç–²ã‚Œæ§˜"
            ],
            "family": [
                "å®¶æ—", "çˆ¶", "æ¯", "å…„", "å§‰", "å¼Ÿ", "å¦¹", "ç¥–çˆ¶", "ç¥–æ¯", "å¤«", "å¦»",
                "æ¯å­", "å¨˜", "å‹é”", "å…ˆç”Ÿ", "å­¦ç”Ÿ", "ä¼šç¤¾å“¡", "åŒ»è€…", "çœ‹è­·å¸«"
            ],
            "food": [
                "é£Ÿã¹ç‰©", "ã”é£¯", "ãƒ‘ãƒ³", "å¯¿å¸", "ãƒ©ãƒ¼ãƒ¡ãƒ³", "ã†ã©ã‚“", "ãã°", "å¤©ã·ã‚‰",
                "åˆºèº«", "ç„¼è‚‰", "ã‚«ãƒ¬ãƒ¼", "å‘³å™Œæ±", "ãŠèŒ¶", "ã‚³ãƒ¼ãƒ’ãƒ¼", "ãƒ“ãƒ¼ãƒ«", "æ°´"
            ]
        }
        
        self.polite_forms = {
            "é£Ÿã¹ã‚‹": "é£Ÿã¹ã¾ã™", "è¡Œã": "è¡Œãã¾ã™", "è¦‹ã‚‹": "è¦‹ã¾ã™", 
            "ã™ã‚‹": "ã—ã¾ã™", "æ¥ã‚‹": "æ¥ã¾ã™"
        }

    async def generate_response(self, user_message: str, user_id: int) -> str:
        """Advanced Japanese AI response"""
        words = user_message.split()
        
        # Handle complex sentences
        if len(words) > 5:
            return self.handle_complex_japanese(user_message)
        
        # Check for vocabulary matches
        for category, vocab_list in self.vocabulary.items():
            for word in vocab_list:
                if word in user_message:
                    return self.explain_japanese_vocabulary(word, category)
        
        # Check for script types
        has_hiragana = bool(re.search(r'[ã²-ã‚“]', user_message))
        has_katakana = bool(re.search(r'[ã‚¢-ãƒ³]', user_message))
        has_kanji = bool(re.search(r'[ä¸€-é¾¯]', user_message))
        
        if has_kanji or has_hiragana or has_katakana:
            return f"æ—¥æœ¬èªã§æ›¸ã„ã¦ã„ã¾ã™ã­ï¼ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼{'æ¼¢å­—' if has_kanji else ''}{'ã²ã‚‰ãŒãª' if has_hiragana else ''}{'ã‚«ã‚¿ã‚«ãƒŠ' if has_katakana else ''}ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã£ã¨è©³ã—ãé•·ã„æ–‡ç« ã§è©±ã—ã¦ãã ã•ã„ï¼"
        
        # Default response
        vocab_sample = random.sample(self.vocabulary["greetings"], 4)
        return f"ã“ã‚“ã«ã¡ã¯ï¼æ—¥æœ¬èªã‚’ä¸€ç·’ã«å‹‰å¼·ã—ã¾ã—ã‚‡ã†ï¼ä»Šæ—¥ã®è¡¨ç¾: {', '.join(vocab_sample)}. é•·ã„æ–‡ç« ã§è³ªå•ã—ã¦ãã ã•ã„ï¼"

    def handle_complex_japanese(self, message: str) -> str:
        """Handle complex Japanese sentences"""
        response = "ã¨ã¦ã‚‚ä¸Šæ‰‹ãªæ—¥æœ¬èªã§ã™ã­ï¼"
        
        # Analyze script usage
        has_hiragana = bool(re.search(r'[ã²-ã‚“]', message))
        has_katakana = bool(re.search(r'[ã‚¢-ãƒ³]', message))
        has_kanji = bool(re.search(r'[ä¸€-é¾¯]', message))
        
        if has_kanji:
            response += "æ¼¢å­—ã‚‚æ­£ã—ãä½¿ãˆã¦ã„ã¾ã™ï¼"
        if has_hiragana:
            response += "ã²ã‚‰ãŒãªã®ä½¿ã„æ–¹ã‚‚å®Œç’§ã§ã™ï¼"
        if has_katakana:
            response += "ã‚«ã‚¿ã‚«ãƒŠã‚‚é©åˆ‡ã«ä½¿ã£ã¦ã„ã¾ã™ã­ï¼"
        
        # Find vocabulary matches
        matched_vocab = []
        for category, vocab_list in self.vocabulary.items():
            for word in vocab_list:
                if word in message:
                    matched_vocab.append(word)
        
        if matched_vocab:
            response += f"'{', '.join(matched_vocab[:3])}'ã¨ã„ã†è¨€è‘‰ã‚’ä½¿ã£ã¦ã„ã¾ã™ã­ã€‚"
        
        response += "ã‚‚ã£ã¨æ—¥æœ¬èªã§è©³ã—ãè©±ã—ã¦ãã ã•ã„ã€‚æ–‡æ³•ã¨èªå½™ã‚’è©³ã—ãèª¬æ˜ã—ã¾ã™ï¼"
        return response

    def explain_japanese_vocabulary(self, word: str, category: str) -> str:
        """Explain Japanese vocabulary with cultural context"""
        if category == "food":
            return f"'{word}'ã¯ç¾å‘³ã—ã„æ—¥æœ¬æ–™ç†ã§ã™ã­ï¼æ–‡åŒ–çš„ãªèª¬æ˜: æ—¥æœ¬äººã¯é£Ÿäº‹ã®å‰ã«'ã„ãŸã ãã¾ã™'ã€å¾Œã«'ã”ã¡ãã†ã•ã¾'ã¨è¨€ã„ã¾ã™ã€‚ä¾‹æ–‡ã‚’ä½œã£ã¦ã¿ã¦ãã ã•ã„: '{word}ã‚’é£Ÿã¹ãŸã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ' '{word}ã¯ã©ã‚“ãªå‘³ã§ã™ã‹ï¼Ÿ' ã‚‚ã£ã¨è©³ã—ãæ—¥æœ¬èªã§æ•™ãˆã¦ãã ã•ã„ï¼"
        
        elif category == "family":
            return f"'{word}'ã¯å®¶æ—ã®è¡¨ç¾ã§ã™ã­ï¼æ—¥æœ¬ã§ã¯å®¶æ—é–¢ä¿‚ã®æ•¬èªãŒé‡è¦ã§ã™ã€‚ä¾‹: '{word}ã¯ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ' å®¶æ—ã«ã¤ã„ã¦é•·ã„æ–‡ç« ã§è©±ã—ã¦ãã ã•ã„ï¼æ•¬èªã‚‚ä½¿ã£ã¦ã¿ã¦ãã ã•ã„ã€‚"
        
        else:
            related_words = self.vocabulary[category][:5]
            return f"'{word}'ã„ã„å˜èªã§ã™ã­ï¼é–¢é€£èªå½™: {', '.join(related_words)}. ã“ã®å˜èªã‚’ä½¿ã£ã¦é•·ã„ä¾‹æ–‡ã‚’ä½œã£ã¦ã¿ã¦ãã ã•ã„ï¼"


# Global AI instances
korean_ai = KoreanAI()
japanese_ai = JapaneseAI()

def get_korean_response(message: str, user_id: int = 0) -> str:
    """Get Korean AI response"""
    import asyncio
    return asyncio.run(korean_ai.generate_response(message, user_id))

def get_japanese_response(message: str, user_id: int = 0) -> str:
    """Get Japanese AI response"""
    import asyncio
    return asyncio.run(japanese_ai.generate_response(message, user_id))